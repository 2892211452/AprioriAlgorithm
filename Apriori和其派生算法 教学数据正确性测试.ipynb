{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frozenset() 返回一个冻结的集合，冻结后集合不能再添加或删除任何元素。\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def loadDataSet():\n",
    "    '''创建一个用于测试的简单的数据集'''\n",
    "\n",
    "    data = pd.read_csv(\"train.csv\")\n",
    "    data = data.sample(1000)\n",
    "#     import copy\n",
    "#     data = data.append(copy.deepcopy(data))\n",
    "#     data = data.append(copy.deepcopy(data))\n",
    "#     data = data.append(copy.deepcopy(data))\n",
    "#     data = data.append(copy.deepcopy(data))\n",
    "#     data = data.append(copy.deepcopy(data)) # 将数据扩大8倍\n",
    "    print(data.shape)\n",
    "    def gerDoodAndBad(score):\n",
    "        ans = []\n",
    "\n",
    "        # math judge\n",
    "        if score['math score'] > 80:\n",
    "            ans.append('MG')\n",
    "        elif score['math score'] < 60:\n",
    "            ans.append('MB')\n",
    "\n",
    "        # reading judge\n",
    "        if score['reading score'] > 85:\n",
    "            ans.append('RG')\n",
    "        elif score['reading score'] < 50:\n",
    "            ans.append('RB')\n",
    "\n",
    "        # writing judge\n",
    "        if score['writing score'] > 85:\n",
    "            ans.append('WG')\n",
    "        elif score['writing score'] < 50:\n",
    "            ans.append('WB')\n",
    "\n",
    "        if score['test preparation course'] == 1:\n",
    "            ans.append(\"preparation\")\n",
    "\n",
    "        return ans\n",
    "\n",
    "    data['Apriori'] = data.apply(lambda x: gerDoodAndBad(x), axis=1)\n",
    "#     print(data.head())\n",
    "\n",
    "    return np.array(data['Apriori'])\n",
    "\n",
    "\n",
    "def loadTest():\n",
    "    testD = pd.read_csv('testData')\n",
    "    testD = testD.sample(500)\n",
    "    print(testD.shape)\n",
    "    npt = np.array(testD)\n",
    "    npt\n",
    "    return npt\n",
    "\n",
    "\n",
    "# 返回只有单个元素的候选集\n",
    "def createC1(dataSet):\n",
    "    '''\n",
    "        构建初始候选项集的列表，即所有候选项集只包含一个元素，\n",
    "        C1是大小为1的所有候选项集的集合\n",
    "    '''\n",
    "    C1 = []\n",
    "    for transaction in dataSet:\n",
    "        for item in transaction:\n",
    "            if [item] not in C1:\n",
    "                C1.append([item])\n",
    "    C1.sort()\n",
    "    # return map( frozenset, C1 )\n",
    "    # return [var for var in map(frozenset,C1)]\n",
    "    return [frozenset(var) for var in C1]\n",
    "\n",
    "\n",
    "def scanD(D, Ck, minSupport):\n",
    "    '''\n",
    "        计算Ck中的项集在数据集合D(记录或者transactions)中的支持度,\n",
    "        返回满足最小支持度的项集的集合，和所有项集支持度信息的字典。\n",
    "    '''\n",
    "    print(len(Ck))\n",
    "    ssCnt = {}\n",
    "    for tid in D:  # 对于每一条transaction\n",
    "        for can in Ck:  # 对于每一个候选项集can，检查是否是transaction的一部分 # 即该候选can是否得到transaction的支持\n",
    "            flag = True\n",
    "            for i in can:\n",
    "                if i not in tid:\n",
    "                    flag = False\n",
    "                    \n",
    "            if flag:\n",
    "                ssCnt[can] = ssCnt.get(can, 0) + 1\n",
    "                \n",
    "#             if can.issubset(tid):\n",
    "#                 ssCnt[can] = ssCnt.get(can, 0) + 1\n",
    "    numItems = float(len(D))\n",
    "    # print(\"ssCnt is\",ssCnt)\n",
    "    retList = []\n",
    "    supportData = {}\n",
    "    for key in ssCnt:\n",
    "        support = ssCnt[key] / numItems  # 每个项集的支持度\n",
    "        if support >= minSupport:  # 将满足最小支持度的项集，加入retList\n",
    "            retList.insert(0, key)\n",
    "        supportData[key] = support  # 汇总支持度数据\n",
    "    return retList, supportData\n",
    "\n",
    "\n",
    "def aprioriGen(Lk, k):  # Aprior算法\n",
    "    '''\n",
    "        由初始候选项集的集合Lk生成新的生成候选项集，\n",
    "        k表示生成的新项集中所含有的元素个数\n",
    "        注意其生成的过程中，首选对每个项集按元素排序，然后每次比较两个项集，只有在前k-1项相同时才将这两项合并。这样做是因为函数并非要两两合并各个集合，那样生成的集合并非都是k+1项的。在限制项数为k+1的前提下，只有在前k-1项相同、最后一项不相同的情况下合并才为所需要的新候选项集。\n",
    "    '''\n",
    "    retList = set()\n",
    "    lenLk = len(Lk)\n",
    "    for i in range(lenLk):\n",
    "        for j in range(i + 1, lenLk):\n",
    "            \n",
    "            L1 = Lk[i]\n",
    "            L2 = Lk[j]\n",
    "            cnt =0\n",
    "            for m in L1:\n",
    "                if m in L2:\n",
    "                    cnt+=1\n",
    "            if cnt == k-2:\n",
    "                retList.add(Lk[i] | Lk[j])\n",
    "    return retList\n",
    "\n",
    "\n",
    "def apriori(dataSet, minSupport=0.5):\n",
    "    \"\"\"\n",
    "    该函数为Apriori算法的主函数，按照前述伪代码的逻辑执行。Ck表示项数为k的候选项集，最初的C1通过createC1()函数生成。Lk表示项数为k的频繁项集，supK为其支持度，Lk和supK由scanD()函数通过Ck计算而来。\n",
    "    :param dataSet:\n",
    "    :param minSupport:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    C1 = createC1(\n",
    "        dataSet)  # 构建初始候选项集C1  [frozenset({1}), frozenset({2}), frozenset({3}), frozenset({4}), frozenset({5})]\n",
    "\n",
    "    D = [set(var) for var in dataSet]  # 集合化数据集\n",
    "    L1, suppData = scanD(D, C1, minSupport)  # 构建初始的频繁项集，即所有项集只有一个元素\n",
    "    L = [L1]  # 最初的L1中的每个项集含有一个元素，新生成的\n",
    "    # print()\n",
    "    k = 2  # 项集应该含有2个元素，所以 k=2\n",
    "\n",
    "    while (len(L[k - 2]) > 0):\n",
    "        t = time.time()\n",
    "        Ck = aprioriGen(L[k - 2], k)\n",
    "        print(f'gen coast:{time.time() - t:.8f}s')\n",
    "        \n",
    "        t = time.time()\n",
    "        Lk, supK = scanD(D, Ck, minSupport) # 筛选最小支持度的频繁项集\n",
    "        print(f'scan coast:{time.time() - t:.8f}s')\n",
    "        # print(\"iter is \")\n",
    "        # print(Ck)\n",
    "        # print(Lk)\n",
    "        # print()\n",
    "        suppData.update(supK)  # 将新的项集的支持度数据加入原来的总支持度字典中\n",
    "        L.append(Lk)  # 将符合最小支持度要求的项集加入L\n",
    "        k += 1  # 新生成的项集中的元素个数应不断增加\n",
    "    return L, suppData  # 返回所有满足条件的频繁项集的列表，和所有候选项集的支持度信息\n",
    "\n",
    "\n",
    "def calcConf(freqSet, H, supportData, brl, minConf=0.7):  # 规则生成与评价\n",
    "    '''\n",
    "        计算规则的可信度，返回满足最小可信度的规则。\n",
    "        freqSet(frozenset):频繁项集\n",
    "        H(frozenset):频繁项集中所有的元素\n",
    "        supportData(dic):频繁项集中所有元素的支持度\n",
    "        brl(tuple):满足可信度条件的关联规则\n",
    "        minConf(float):最小可信度\n",
    "    '''\n",
    "    prunedH = []\n",
    "    for conseq in H:\n",
    "        conf = supportData[freqSet] / supportData[freqSet - conseq]\n",
    "        if conf >= minConf:\n",
    "            print(freqSet - conseq, '-->', conseq, 'conf:', conf)\n",
    "            brl.append((freqSet - conseq, conseq, conf))\n",
    "            prunedH.append(conseq)\n",
    "    return prunedH\n",
    "\n",
    "\n",
    "def rulesFromConseq(freqSet, H, supportData, brl, minConf=0.7):\n",
    "    '''\n",
    "        对频繁项集中元素超过2的项集进行合并。\n",
    "        freqSet(frozenset):频繁项集\n",
    "        H(frozenset):频繁项集中的所有元素，即可以出现在规则右部的元素\n",
    "        supportData(dict):所有项集的支持度信息\n",
    "        brl(tuple):生成的规则\n",
    "    '''\n",
    "    m = len(H[0])\n",
    "    if len(freqSet) > m + 1:  # 查看频繁项集是否足够大，以到于移除大小为 m的子集，否则继续生成m+1大小的频繁项集\n",
    "        Hmp1 = aprioriGen(H, m + 1)\n",
    "        Hmp1 = calcConf(freqSet, Hmp1, supportData, brl, minConf)  # 对于新生成的m+1大小的频繁项集，计算新生成的关联规则的右则的集合\n",
    "        if len(Hmp1) > 1:  # 如果不止一条规则满足要求（新生成的关联规则的右则的集合的大小大于1），进一步递归合并，\n",
    "            # 这样做的结果就是会有“[1|多]->多”(右边只会是“多”，因为合并的本质是频繁子项集变大，\n",
    "            # 而calcConf函数的关联结果的右侧就是频繁子项集）的关联结果\n",
    "            rulesFromConseq(freqSet, Hmp1, supportData, brl, minConf)\n",
    "\n",
    "\n",
    "def generateRules(L, supportData, minConf=0.7):\n",
    "    '''\n",
    "        根据频繁项集和最小可信度生成规则。\n",
    "        L(list):存储频繁项集\n",
    "        supportData(dict):存储着所有项集（不仅仅是频繁项集）的支持度\n",
    "        minConf(float):最小可信度\n",
    "    '''\n",
    "    bigRuleList = []\n",
    "    for i in range(1, len(L)):\n",
    "        for freqSet in L[i]:  # 对于每一个频繁项集的集合freqSet\n",
    "            H1 = [frozenset([item]) for item in freqSet]\n",
    "            if i > 1:  # 如果频繁项集中的元素个数大于2，需要进一步合并，这样做的结果就是会有“[1|多]->多”(右边只会是“多”，\n",
    "                # 因为合并的本质是频繁子项集变大，而calcConf函数的关联结果的右侧就是频繁子项集），的关联结果\n",
    "                rulesFromConseq(freqSet, H1, supportData, bigRuleList, minConf)\n",
    "            else:\n",
    "                calcConf(freqSet, H1, supportData, bigRuleList, minConf)\n",
    "\n",
    "    sorted(bigRuleList)\n",
    "    return bigRuleList\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 16)\n"
     ]
    }
   ],
   "source": [
    "myDat = loadDataSet()  # 导入数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "gen coast:0.00000000s\n",
      "21\n",
      "scan coast:0.01296520s\n",
      "gen coast:0.00000000s\n",
      "14\n",
      "scan coast:0.01097107s\n",
      "gen coast:0.00000000s\n",
      "1\n",
      "scan coast:0.00100446s\n",
      "gen coast:0.00000000s\n",
      "0\n",
      "scan coast:0.00000000s\n",
      "花费的时间为:0.03544450s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "t = time.time()\n",
    "\n",
    "L, suppData = apriori(myDat, 0.05)  # 选择频繁项集\n",
    "# print(u\"频繁项集L：\", suppData)\n",
    "# print(u\"所有候选项集的支持度信息：\", suppData)\n",
    "print(f'花费的时间为:{time.time() - t:.8f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'RG'}) --> frozenset({'MG'}) conf: 0.6590909090909091\n",
      "frozenset({'WG'}) --> frozenset({'MG'}) conf: 0.7107438016528925\n",
      "frozenset({'MG'}) --> frozenset({'preparation'}) conf: 0.5227272727272727\n",
      "frozenset({'WB'}) --> frozenset({'preparation'}) conf: 0.8596491228070176\n",
      "frozenset({'RB'}) --> frozenset({'preparation'}) conf: 0.8222222222222222\n",
      "frozenset({'WB'}) --> frozenset({'MB'}) conf: 0.9385964912280701\n",
      "frozenset({'RB'}) --> frozenset({'MB'}) conf: 0.9222222222222223\n",
      "frozenset({'WB'}) --> frozenset({'RB'}) conf: 0.6842105263157895\n",
      "frozenset({'RB'}) --> frozenset({'WB'}) conf: 0.8666666666666667\n",
      "frozenset({'RG'}) --> frozenset({'WG'}) conf: 0.7424242424242424\n",
      "frozenset({'WG'}) --> frozenset({'RG'}) conf: 0.8099173553719009\n",
      "frozenset({'MB'}) --> frozenset({'preparation'}) conf: 0.7306501547987615\n",
      "frozenset({'RG'}) --> frozenset({'WG', 'MG'}) conf: 0.553030303030303\n",
      "frozenset({'WG'}) --> frozenset({'MG', 'RG'}) conf: 0.6033057851239669\n",
      "frozenset({'RB'}) --> frozenset({'WB', 'preparation'}) conf: 0.7333333333333334\n",
      "frozenset({'WB'}) --> frozenset({'RB', 'preparation'}) conf: 0.5789473684210527\n",
      "frozenset({'RB'}) --> frozenset({'preparation', 'MB'}) conf: 0.7555555555555556\n",
      "frozenset({'RB'}) --> frozenset({'WB', 'MB'}) conf: 0.8222222222222222\n",
      "frozenset({'WB'}) --> frozenset({'RB', 'MB'}) conf: 0.6491228070175438\n",
      "frozenset({'WB'}) --> frozenset({'preparation', 'MB'}) conf: 0.8070175438596491\n",
      "frozenset({'WB', 'preparation'}) --> frozenset({'RB', 'MB'}) conf: 0.6428571428571428\n",
      "frozenset({'WB', 'MB'}) --> frozenset({'RB', 'preparation'}) conf: 0.588785046728972\n",
      "frozenset({'RB', 'preparation'}) --> frozenset({'WB', 'MB'}) conf: 0.8513513513513514\n",
      "frozenset({'RB', 'MB'}) --> frozenset({'WB', 'preparation'}) conf: 0.7590361445783133\n",
      "frozenset({'RB', 'WB'}) --> frozenset({'preparation', 'MB'}) conf: 0.8076923076923077\n",
      "frozenset({'RB'}) --> frozenset({'WB', 'preparation', 'MB'}) conf: 0.7000000000000001\n",
      "frozenset({'WB'}) --> frozenset({'RB', 'preparation', 'MB'}) conf: 0.5526315789473684\n"
     ]
    }
   ],
   "source": [
    "rules = generateRules(L, suppData, minConf=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "频繁项集如下:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([[frozenset({'RB'}),\n",
       "   frozenset({'WB'}),\n",
       "   frozenset({'MB'}),\n",
       "   frozenset({'preparation'}),\n",
       "   frozenset({'WG'}),\n",
       "   frozenset({'RG'}),\n",
       "   frozenset({'MG'})],\n",
       "  [frozenset({'RB', 'WB'}),\n",
       "   frozenset({'MB', 'RB'}),\n",
       "   frozenset({'RB', 'preparation'}),\n",
       "   frozenset({'WB', 'preparation'}),\n",
       "   frozenset({'MB', 'WB'}),\n",
       "   frozenset({'MB', 'preparation'}),\n",
       "   frozenset({'MG', 'WG'}),\n",
       "   frozenset({'RG', 'WG'}),\n",
       "   frozenset({'MG', 'RG'}),\n",
       "   frozenset({'RG', 'preparation'}),\n",
       "   frozenset({'MG', 'preparation'})],\n",
       "  [frozenset({'RB', 'WB', 'preparation'}),\n",
       "   frozenset({'MB', 'RB', 'WB'}),\n",
       "   frozenset({'MB', 'RB', 'preparation'}),\n",
       "   frozenset({'MB', 'WB', 'preparation'}),\n",
       "   frozenset({'MG', 'RG', 'WG'})],\n",
       "  [frozenset({'MB', 'RB', 'WB', 'preparation'})],\n",
       "  []],\n",
       " {frozenset({'MG'}): 0.176,\n",
       "  frozenset({'RG'}): 0.132,\n",
       "  frozenset({'WG'}): 0.121,\n",
       "  frozenset({'preparation'}): 0.642,\n",
       "  frozenset({'MB'}): 0.323,\n",
       "  frozenset({'WB'}): 0.114,\n",
       "  frozenset({'RB'}): 0.09,\n",
       "  frozenset({'MG', 'preparation'}): 0.092,\n",
       "  frozenset({'RG', 'preparation'}): 0.064,\n",
       "  frozenset({'MG', 'RG'}): 0.087,\n",
       "  frozenset({'RG', 'WG'}): 0.098,\n",
       "  frozenset({'MG', 'WG'}): 0.086,\n",
       "  frozenset({'WG', 'preparation'}): 0.047,\n",
       "  frozenset({'MB', 'preparation'}): 0.236,\n",
       "  frozenset({'MB', 'WB'}): 0.107,\n",
       "  frozenset({'WB', 'preparation'}): 0.098,\n",
       "  frozenset({'RB', 'preparation'}): 0.074,\n",
       "  frozenset({'MB', 'RB'}): 0.083,\n",
       "  frozenset({'RB', 'WB'}): 0.078,\n",
       "  frozenset({'MG', 'RG', 'WG'}): 0.073,\n",
       "  frozenset({'MG', 'RG', 'preparation'}): 0.041,\n",
       "  frozenset({'RG', 'WG', 'preparation'}): 0.04,\n",
       "  frozenset({'MG', 'WG', 'preparation'}): 0.035,\n",
       "  frozenset({'MB', 'WB', 'preparation'}): 0.092,\n",
       "  frozenset({'MB', 'RB', 'preparation'}): 0.068,\n",
       "  frozenset({'MB', 'RB', 'WB'}): 0.074,\n",
       "  frozenset({'RB', 'WB', 'preparation'}): 0.066,\n",
       "  frozenset({'MB', 'RB', 'WB', 'preparation'}): 0.063})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"频繁项集如下:\")\n",
    "L, suppData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对规则进行排序后输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(frozenset({'WB'}), frozenset({'MB'}), 0.9385964912280701),\n",
       " (frozenset({'RB'}), frozenset({'MB'}), 0.9222222222222223),\n",
       " (frozenset({'RB'}), frozenset({'WB'}), 0.8666666666666667),\n",
       " (frozenset({'WB'}), frozenset({'preparation'}), 0.8596491228070176),\n",
       " (frozenset({'RB', 'preparation'}),\n",
       "  frozenset({'MB', 'WB'}),\n",
       "  0.8513513513513514),\n",
       " (frozenset({'RB'}), frozenset({'preparation'}), 0.8222222222222222),\n",
       " (frozenset({'RB'}), frozenset({'MB', 'WB'}), 0.8222222222222222),\n",
       " (frozenset({'WG'}), frozenset({'RG'}), 0.8099173553719009),\n",
       " (frozenset({'RB', 'WB'}),\n",
       "  frozenset({'MB', 'preparation'}),\n",
       "  0.8076923076923077),\n",
       " (frozenset({'WB'}), frozenset({'MB', 'preparation'}), 0.8070175438596491),\n",
       " (frozenset({'MB', 'RB'}),\n",
       "  frozenset({'WB', 'preparation'}),\n",
       "  0.7590361445783133),\n",
       " (frozenset({'RB'}), frozenset({'MB', 'preparation'}), 0.7555555555555556),\n",
       " (frozenset({'RG'}), frozenset({'WG'}), 0.7424242424242424),\n",
       " (frozenset({'RB'}), frozenset({'WB', 'preparation'}), 0.7333333333333334),\n",
       " (frozenset({'MB'}), frozenset({'preparation'}), 0.7306501547987615),\n",
       " (frozenset({'WG'}), frozenset({'MG'}), 0.7107438016528925),\n",
       " (frozenset({'RB'}),\n",
       "  frozenset({'MB', 'WB', 'preparation'}),\n",
       "  0.7000000000000001),\n",
       " (frozenset({'WB'}), frozenset({'RB'}), 0.6842105263157895),\n",
       " (frozenset({'RG'}), frozenset({'MG'}), 0.6590909090909091),\n",
       " (frozenset({'WB'}), frozenset({'MB', 'RB'}), 0.6491228070175438),\n",
       " (frozenset({'WB', 'preparation'}),\n",
       "  frozenset({'MB', 'RB'}),\n",
       "  0.6428571428571428),\n",
       " (frozenset({'WG'}), frozenset({'MG', 'RG'}), 0.6033057851239669),\n",
       " (frozenset({'MB', 'WB'}),\n",
       "  frozenset({'RB', 'preparation'}),\n",
       "  0.588785046728972),\n",
       " (frozenset({'WB'}), frozenset({'RB', 'preparation'}), 0.5789473684210527),\n",
       " (frozenset({'RG'}), frozenset({'MG', 'WG'}), 0.553030303030303),\n",
       " (frozenset({'WB'}),\n",
       "  frozenset({'MB', 'RB', 'preparation'}),\n",
       "  0.5526315789473684),\n",
       " (frozenset({'MG'}), frozenset({'preparation'}), 0.5227272727272727)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import functools\n",
    "\n",
    "def cmp(a,b):\n",
    "    if a[2] < b[2]:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "    \n",
    "rules = sorted(rules, key=functools.cmp_to_key(cmp))\n",
    "rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**根据以上规则，不难看出：**\n",
    "- 读成绩差的人，那么他其他科目的成绩大概率也差，所以要对读成绩差的人多加以关注。让他们打好基础\n",
    "- 写成绩好的人，那么读成绩大概率也好，要进行混合教育\n",
    "- 数学应该是最难的科目，应该多加以考量，哪怕其他两科成绩都好，数学成绩好的概率也不高"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CBE Apriori二进制编码算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frozenset() 返回一个冻结的集合，冻结后集合不能再添加或删除任何元素。\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "class node:\n",
    "    def __int__(self):\n",
    "        self.items = []\n",
    "        self.key = 0\n",
    "        self.sup = 0\n",
    "    def show(self):\n",
    "        print(self.items, bin(self.key), end=\" \")\n",
    "        try:\n",
    "            print(self.sup)\n",
    "        except:\n",
    "            print()\n",
    "            pass\n",
    "\n",
    "\n",
    "def ListToNode(items):\n",
    "    nodeT = node()\n",
    "    nodeT.key =0\n",
    "    nodeT.items = items\n",
    "    for index,i in enumerate(defaultSL): # 进行编码\n",
    "        if i in items:\n",
    "            nodeT.key += 1 << (len(defaultSL) - index -1)\n",
    "    return nodeT\n",
    "\n",
    "\n",
    "def keyToList(key):\n",
    "    ans =[]\n",
    "    global defaultSL\n",
    "    for i in range(1,len(defaultSL) +1):\n",
    "        if key  & (1 << (len(defaultSL)) - i) == (1 << (len(defaultSL)) - i): # 含有第i个\n",
    "            ans.append(defaultSL[i-1])\n",
    "    return ans\n",
    "\n",
    "\n",
    "def loadDataSet():\n",
    "    '''创建一个用于测试的简单的数据集'''\n",
    "\n",
    "    data = pd.read_csv(\"train.csv\")\n",
    "    data = data.sample(1000)\n",
    "#     import copy\n",
    "#     data = data.append(copy.deepcopy(data))\n",
    "#     data = data.append(copy.deepcopy(data))\n",
    "#     data = data.append(copy.deepcopy(data))\n",
    "#     data = data.append(copy.deepcopy(data))\n",
    "#     data = data.append(copy.deepcopy(data)) # 将数据扩大8倍\n",
    "    print(data.shape)\n",
    "    def gerDoodAndBad(score):\n",
    "        ans = []\n",
    "\n",
    "        # math judge\n",
    "        if score['math score'] > 80:\n",
    "            ans.append('MG')\n",
    "        elif score['math score'] < 60:\n",
    "            ans.append('MB')\n",
    "\n",
    "        # reading judge\n",
    "        if score['reading score'] > 85:\n",
    "            ans.append('RG')\n",
    "        elif score['reading score'] < 50:\n",
    "            ans.append('RB')\n",
    "\n",
    "        # writing judge\n",
    "        if score['writing score'] > 85:\n",
    "            ans.append('WG')\n",
    "        elif score['writing score'] < 50:\n",
    "            ans.append('WB')\n",
    "\n",
    "        if score['test preparation course'] == 1:\n",
    "            ans.append(\"preparation\")\n",
    "\n",
    "        return ans\n",
    "\n",
    "    data['Apriori'] = data.apply(lambda x: gerDoodAndBad(x), axis=1)\n",
    "#     print(data.head())\n",
    "\n",
    "    return np.array(data['Apriori'])\n",
    "\n",
    "def loadTest():\n",
    "    testD = pd.read_csv('testData')\n",
    "    testD = testD.sample(500)\n",
    "    testD.shape\n",
    "    npt = np.array(testD)\n",
    "    npt\n",
    "    return npt\n",
    "\n",
    "# 返回只有单个元素的候选集\n",
    "def createC1(dataSet):\n",
    "    '''\n",
    "        构建初始候选项集的列表，即所有候选项集只包含一个元素，\n",
    "        C1是大小为1的所有候选项集的集合\n",
    "    '''\n",
    "    C1 = []\n",
    "    for transaction in dataSet:\n",
    "        for item in transaction:\n",
    "            if [item] not in C1:\n",
    "                C1.append([item])\n",
    "    C1.sort()\n",
    "    # return map( frozenset, C1 )\n",
    "    # return [var for var in map(frozenset,C1)]\n",
    "    return [frozenset(var) for var in C1]\n",
    "\n",
    "\n",
    "def scanD(D, Ck, minSupport):\n",
    "    '''\n",
    "        计算Ck中的项集在数据集合D(记录或者transactions)中的支持度,\n",
    "        返回满足最小支持度的项集的集合，和所有项集支持度信息的字典。\n",
    "    '''\n",
    "    print(len(Ck))\n",
    "\n",
    "    for i in Ck:\n",
    "        i.sup =0\n",
    "        for item in D:\n",
    "            if i.key & item.key == i.key: #与运算判断子集\n",
    "                i.sup +=1\n",
    "    ans =[]\n",
    "    length = len(D)\n",
    "    for i in Ck:\n",
    "        i.sup = i.sup / length\n",
    "        if i.sup >= minSupport:\n",
    "            ans.append(i)\n",
    "            # i.show()\n",
    "    return ans\n",
    "\n",
    "\n",
    "\n",
    "def aprioriGen(Lk, k):  # Aprior算法\n",
    "    '''\n",
    "        由初始候选项集的集合Lk生成新的生成候选项集，\n",
    "        k表示生成的新项集中所含有的元素个数\n",
    "        注意其生成的过程中，首选对每个项集按元素排序，然后每次比较两个项集，只有在前k-1项相同时才将这两项合并。这样做是因为函数并非要两两合并各个集合，那样生成的集合并非都是k+1项的。在限制项数为k+1的前提下，只有在前k-1项相同、最后一项不相同的情况下合并才为所需要的新候选项集。\n",
    "    '''\n",
    "\n",
    "    global twoDif\n",
    "\n",
    "    retList = []\n",
    "    lenLk = len(Lk)\n",
    "    nowSet = set()\n",
    "    for i in range(lenLk):\n",
    "        for j in range(i + 1, lenLk):\n",
    "\n",
    "            a = Lk[i]\n",
    "            b = Lk[j]\n",
    "            t = a.key ^ b.key\n",
    "            #要注意候选集以及去重的问题\n",
    "            if t in twoDif:\n",
    "\n",
    "                \n",
    "                tkey = a.key | b.key\n",
    "                if tkey not in nowSet:\n",
    "                    nodeT = node()\n",
    "                    nodeT.key = tkey\n",
    "                    nowSet.add(nodeT.key)\n",
    "                    # a.show()\n",
    "                    # b.show()\n",
    "                    nodeT.items = keyToList(nodeT.key)  #生成新的items\n",
    "                    retList.append(nodeT)\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "    return retList\n",
    "\n",
    "\n",
    "def apriori(dataSet, minSupport=0.5):\n",
    "    \"\"\"\n",
    "    该函数为Apriori算法的主函数，按照前述伪代码的逻辑执行。Ck表示项数为k的候选项集，最初的C1通过createC1()函数生成。Lk表示项数为k的频繁项集，supK为其支持度，Lk和supK由scanD()函数通过Ck计算而来。\n",
    "    :param dataSet:\n",
    "    :param minSupport:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # C1 = createC1(dataSet)  # 构建初始候选项集C1  [frozenset({1}), frozenset({2}), frozenset({3}), frozenset({4}), frozenset({5})]\n",
    "    global defaultSL\n",
    "    global defaultS\n",
    "\n",
    "#     print(defaultSL)\n",
    "    C1 = [ListToNode([i]) for i in defaultSL]\n",
    "\n",
    "\n",
    "    # D = [set(var) for var in dataSet]  # 集合化数据集\n",
    "\n",
    "    F1 = scanD(dataSet, C1, minSupport)  # 构建初始的频繁项集，即所有项集只有一个元素\n",
    "\n",
    "    # print()\n",
    "    L = [F1]\n",
    "    k = 2  # 项集应该含有2个元素，所以 k=2\n",
    "\n",
    "    while (len(L[k - 2]) > 0):\n",
    "        t= time.time()\n",
    "        Ck = aprioriGen(L[k - 2], k) # 计算候选集\n",
    "        print(f'gen coast:{time.time() - t:.8f}s')\n",
    "        t = time.time()\n",
    "        \n",
    "        Fk= scanD(dataSet, Ck, minSupport) # 筛选最小支持度的频繁项集\n",
    "        print(f'scan coast:{time.time() - t:.8f}s')\n",
    "\n",
    "        L.append(Fk)  # 将符合最小支持度要求的项集加入L\n",
    "        k += 1  # 新生成的项集中的元素个数应不断增加\n",
    "    return L  # 返回所有满足条件的频繁项集的列表，和所有候选项集的支持度信息\n",
    "\n",
    "\n",
    "def calcConf(freqSet, H, supportData, brl, minConf=0.7):  # 规则生成与评价\n",
    "    '''\n",
    "        计算规则的可信度，返回满足最小可信度的规则。\n",
    "        freqSet(frozenset):频繁项集\n",
    "        H(frozenset):频繁项集中所有的元素\n",
    "        supportData(dic):频繁项集中所有元素的支持度\n",
    "        brl(tuple):满足可信度条件的关联规则\n",
    "        minConf(float):最小可信度\n",
    "    '''\n",
    "    prunedH = []\n",
    "    for conseq in H:\n",
    "        conf = supportData[freqSet] / supportData[freqSet - conseq]\n",
    "        if conf >= minConf:\n",
    "            print(freqSet - conseq, '-->', conseq, 'conf:', conf)\n",
    "            brl.append((freqSet - conseq, conseq, conf))\n",
    "            prunedH.append(conseq)\n",
    "    return prunedH\n",
    "\n",
    "\n",
    "def rulesFromConseq(freqSet, H, supportData, brl, minConf=0.7):\n",
    "    '''\n",
    "        对频繁项集中元素超过2的项集进行合并。\n",
    "        freqSet(frozenset):频繁项集\n",
    "        H(frozenset):频繁项集中的所有元素，即可以出现在规则右部的元素\n",
    "        supportData(dict):所有项集的支持度信息\n",
    "        brl(tuple):生成的规则\n",
    "    '''\n",
    "    m = len(H[0])\n",
    "    if len(freqSet) > m + 1:  # 查看频繁项集是否足够大，以到于移除大小为 m的子集，否则继续生成m+1大小的频繁项集\n",
    "        Hmp1 = aprioriGen(H, m + 1)\n",
    "        Hmp1 = calcConf(freqSet, Hmp1, supportData, brl, minConf)  # 对于新生成的m+1大小的频繁项集，计算新生成的关联规则的右则的集合\n",
    "        if len(Hmp1) > 1:  # 如果不止一条规则满足要求（新生成的关联规则的右则的集合的大小大于1），进一步递归合并，\n",
    "            # 这样做的结果就是会有“[1|多]->多”(右边只会是“多”，因为合并的本质是频繁子项集变大，\n",
    "            # 而calcConf函数的关联结果的右侧就是频繁子项集）的关联结果\n",
    "            rulesFromConseq(freqSet, Hmp1, supportData, brl, minConf)\n",
    "\n",
    "\n",
    "def generateRules(L, supportData, minConf=0.7):\n",
    "    '''\n",
    "        根据频繁项集和最小可信度生成规则。\n",
    "        L(list):存储频繁项集\n",
    "        supportData(dict):存储着所有项集（不仅仅是频繁项集）的支持度\n",
    "        minConf(float):最小可信度\n",
    "    '''\n",
    "    bigRuleList = []\n",
    "    for i in range(1, len(L)):\n",
    "        for freqSet in L[i]:  # 对于每一个频繁项集的集合freqSet\n",
    "            H1 = [frozenset([item]) for item in freqSet]\n",
    "            if i > 1:  # 如果频繁项集中的元素个数大于2，需要进一步合并，这样做的结果就是会有“[1|多]->多”(右边只会是“多”，\n",
    "                # 因为合并的本质是频繁子项集变大，而calcConf函数的关联结果的右侧就是频繁子项集），的关联结果\n",
    "                rulesFromConseq(freqSet, H1, supportData, bigRuleList, minConf)\n",
    "            else:\n",
    "                calcConf(freqSet, H1, supportData, bigRuleList, minConf)\n",
    "\n",
    "    sorted(bigRuleList)\n",
    "    return bigRuleList\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 16)\n",
      "['MB', 'MG', 'RB', 'RG', 'WB', 'WG', 'preparation'] 7\n"
     ]
    }
   ],
   "source": [
    "defaultS = set()  # 存储所有单项的集合\n",
    "myDat = loadDataSet()  # 导入数据集\n",
    "for i in myDat:\n",
    "    for j in i:\n",
    "        if j not in defaultS:\n",
    "            defaultS.add(j)\n",
    "defaultSL = list(defaultS)\n",
    "defaultSL = sorted(defaultSL) # 把所有单项计算出来并排序，形成默认顺序，方便后面进行二进制编码\n",
    "print(defaultSL, len(defaultSL))\n",
    "Items = []\n",
    "\n",
    "\n",
    "\n",
    "#对项集进行二进制编码\n",
    "for items in myDat:\n",
    "    nodeT = node()\n",
    "    nodeT.key =0\n",
    "    nodeT.items = items\n",
    "    for index,i in enumerate(defaultSL): # 进行编码\n",
    "        if i in items:\n",
    "            nodeT.key += 1 << (len(defaultSL) - index -1)\n",
    "    Items.append(nodeT)\n",
    "    # print(items, bin(nodeT.key))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "得到默认编码序列['MB', 'MG', 'RB', 'RG', 'WB', 'WG', 'preparation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0b11\n",
      "0b101\n",
      "0b110\n",
      "0b1001\n",
      "0b1010\n",
      "0b1100\n",
      "0b10001\n",
      "0b10010\n",
      "0b10100\n",
      "0b11000\n",
      "0b100001\n",
      "0b100010\n",
      "0b100100\n",
      "0b101000\n",
      "0b110000\n",
      "0b1000001\n",
      "0b1000010\n",
      "0b1000100\n",
      "0b1001000\n",
      "0b1010000\n",
      "0b1100000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "twoDif =set() # 计算仅仅两个不同时的二进制集合\n",
    "length = len(defaultSL)\n",
    "for i in range(length):\n",
    "    for j in range(length):\n",
    "        if i != j:\n",
    "            t=0\n",
    "#             print(i,j)\n",
    "            t = 1<<(i) \n",
    "            t+=1<<(j)\n",
    "#             print(bin(t))\n",
    "            twoDif.add(t)\n",
    "for i in twoDif:\n",
    "    print(bin(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "gen coast:0.00099635s\n",
      "21\n",
      "scan coast:0.00903368s\n",
      "gen coast:0.00000000s\n",
      "14\n",
      "scan coast:0.00898576s\n",
      "gen coast:0.00000000s\n",
      "1\n",
      "scan coast:0.00099349s\n",
      "gen coast:0.00000000s\n",
      "0\n",
      "scan coast:0.00000000s\n",
      "频繁项集L：\n",
      "['MB'] 0b1000000 0.323\n",
      "['MG'] 0b100000 0.176\n",
      "['RB'] 0b10000 0.09\n",
      "['RG'] 0b1000 0.132\n",
      "['WB'] 0b100 0.114\n",
      "['WG'] 0b10 0.121\n",
      "['preparation'] 0b1 0.642\n",
      "['MB', 'RB'] 0b1010000 0.083\n",
      "['MB', 'WB'] 0b1000100 0.107\n",
      "['MB', 'preparation'] 0b1000001 0.236\n",
      "['MG', 'RG'] 0b101000 0.087\n",
      "['MG', 'WG'] 0b100010 0.086\n",
      "['MG', 'preparation'] 0b100001 0.092\n",
      "['RB', 'WB'] 0b10100 0.078\n",
      "['RB', 'preparation'] 0b10001 0.074\n",
      "['RG', 'WG'] 0b1010 0.098\n",
      "['RG', 'preparation'] 0b1001 0.064\n",
      "['WB', 'preparation'] 0b101 0.098\n",
      "['MB', 'RB', 'WB'] 0b1010100 0.074\n",
      "['MB', 'RB', 'preparation'] 0b1010001 0.068\n",
      "['MB', 'WB', 'preparation'] 0b1000101 0.092\n",
      "['MG', 'RG', 'WG'] 0b101010 0.073\n",
      "['RB', 'WB', 'preparation'] 0b10101 0.066\n",
      "['MB', 'RB', 'WB', 'preparation'] 0b1010101 0.063\n",
      "total coast:0.03889585s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t = time.time()\n",
    "\n",
    "L = apriori(Items, 0.05)  # 选择频繁项集\n",
    "print(u\"频繁项集L：\")\n",
    "for li in L:\n",
    "    for i in li:\n",
    "        i.show()\n",
    "print(f'total coast:{time.time() - t:.8f}s')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 这里对比原生的Apriori算法，可以看出答案是一样的。正确\n",
    "\n",
    "### 关于运行速度对比\n",
    "- 如果采用原生的教学数据集看不出太大差别，因为数据集很小。\n",
    "- 但是如果采用稍微正常一点的不是很稠密的数据集，不难看出。随着最小支持度的减小，二者的差别越来越大\n",
    "- 这里的数据集采用mushroom\n",
    "\n",
    "### 关于运行效率分析\n",
    "这里的数据集特征，\n",
    "- 总计8123条数据,23个特征\n",
    "- 如果数据条数足够大的时候，时间主要集中在gen和scan上，这时候二进制编码的效率就上来了\n",
    "- 当特征太少的时候，二者跑不出太大区别，因为基本都是单项集scan和查找候选集都没有太大差别\n",
    "\n",
    "### 结果\n",
    "\n",
    "当数据集为500,23特征，支持度为0.3\n",
    "- 经典Apriori：21.2s\n",
    "- 二进制Apriori：5.8s\n",
    "\n",
    "3000,23特征，支持度为0.3\n",
    "- 经典Apriori：分钟了\n",
    "- 二进制Apriori：30.2s\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
