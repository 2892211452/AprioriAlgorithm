{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# frozenset() 返回一个冻结的集合，冻结后集合不能再添加或删除任何元素。\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Config import *\n",
    "\n",
    "\n",
    "# 倒入设置参数和加载数据集函数\n",
    "from Config import *\n",
    "\n",
    "\n",
    "\n",
    "# 返回只有单个元素的候选集\n",
    "def createC1(dataSet):\n",
    "    '''\n",
    "        构建初始候选项集的列表，即所有候选项集只包含一个元素，\n",
    "        C1是大小为1的所有候选项集的集合\n",
    "    '''\n",
    "    C1 = []\n",
    "    for transaction in dataSet:\n",
    "        for item in transaction:\n",
    "            if [item] not in C1:\n",
    "                C1.append([item])\n",
    "    C1.sort()\n",
    "    # return map( frozenset, C1 )\n",
    "    # return [var for var in map(frozenset,C1)]\n",
    "    return [frozenset(var) for var in C1]\n",
    "\n",
    "\n",
    "def scanD(D, Ck, minSupport):\n",
    "    '''\n",
    "        计算Ck中的项集在数据集合D(记录或者transactions)中的支持度,\n",
    "        返回满足最小支持度的项集的集合，和所有项集支持度信息的字典。\n",
    "    '''\n",
    "    print(len(Ck))\n",
    "    ssCnt = {}\n",
    "    for tid in D:  # 对于每一条transaction\n",
    "        for can in Ck:  # 对于每一个候选项集can，检查是否是transaction的一部分 # 即该候选can是否得到transaction的支持\n",
    "            flag = True\n",
    "            for i in can:\n",
    "                if i not in tid:\n",
    "                    flag = False\n",
    "                    \n",
    "            if flag:\n",
    "                ssCnt[can] = ssCnt.get(can, 0) + 1\n",
    "                \n",
    "#             if can.issubset(tid):\n",
    "#                 ssCnt[can] = ssCnt.get(can, 0) + 1\n",
    "    numItems = float(len(D))\n",
    "    # print(\"ssCnt is\",ssCnt)\n",
    "    retList = []\n",
    "    supportData = {}\n",
    "    for key in ssCnt:\n",
    "        support = ssCnt[key] / numItems  # 每个项集的支持度\n",
    "        if support >= minSupport:  # 将满足最小支持度的项集，加入retList\n",
    "            retList.insert(0, key)\n",
    "        supportData[key] = support  # 汇总支持度数据\n",
    "    return retList, supportData\n",
    "\n",
    "\n",
    "def aprioriGen(Lk, k):  # Aprior算法\n",
    "    '''\n",
    "        由初始候选项集的集合Lk生成新的生成候选项集，\n",
    "        k表示生成的新项集中所含有的元素个数\n",
    "        注意其生成的过程中，首选对每个项集按元素排序，然后每次比较两个项集，只有在k-1项相同时才将这两项合并。这样做是因为函数并非要两两合并各个集合，那样生成的集合并非都是k+1项的。在限制项数为k+1的前提下，只有在前k-1项相同、最后一项不相同的情况下合并才为所需要的新候选项集。\n",
    "    '''\n",
    "    retList = set()\n",
    "    lenLk = len(Lk)\n",
    "    for i in range(lenLk):\n",
    "        for j in range(i + 1, lenLk):\n",
    "            \n",
    "            L1 = Lk[i]\n",
    "            L2 = Lk[j]\n",
    "            cnt =0\n",
    "            for m in L1:\n",
    "                if m in L2:\n",
    "                    cnt+=1\n",
    "            if cnt == k-2:\n",
    "                retList.add(Lk[i] | Lk[j])\n",
    "    return retList\n",
    "\n",
    "\n",
    "def apriori(dataSet, minSupport=0.5):\n",
    "    \"\"\"\n",
    "    该函数为Apriori算法的主函数，按照前述伪代码的逻辑执行。Ck表示项数为k的候选项集，最初的C1通过createC1()函数生成。Lk表示项数为k的频繁项集，supK为其支持度，Lk和supK由scanD()函数通过Ck计算而来。\n",
    "    :param dataSet:\n",
    "    :param minSupport:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    C1 = createC1(\n",
    "        dataSet)  # 构建初始候选项集C1  [frozenset({1}), frozenset({2}), frozenset({3}), frozenset({4}), frozenset({5})]\n",
    "\n",
    "    D = [set(var) for var in dataSet]  # 集合化数据集\n",
    "    L1, suppData = scanD(D, C1, minSupport)  # 构建初始的频繁项集，即所有项集只有一个元素\n",
    "    L = [L1]  # 最初的L1中的每个项集含有一个元素，新生成的\n",
    "    # print()\n",
    "    k = 2  # 项集应该含有2个元素，所以 k=2\n",
    "\n",
    "    while (len(L[k - 2]) > 0):\n",
    "        print(\"iter is \", k)\n",
    "        t = time.time()\n",
    "        Ck = aprioriGen(L[k - 2], k)\n",
    "        print(f'gen coast:{time.time() - t:.8f}s')\n",
    "        \n",
    "        t = time.time()\n",
    "        Lk, supK = scanD(D, Ck, minSupport) # 筛选最小支持度的频繁项集\n",
    "        print(f'scan coast:{time.time() - t:.8f}s')\n",
    "        # print(\"iter is \")\n",
    "        # print(Ck)\n",
    "        # print(Lk)\n",
    "        # print()\n",
    "        suppData.update(supK)  # 将新的项集的支持度数据加入原来的总支持度字典中\n",
    "        L.append(Lk)  # 将符合最小支持度要求的项集加入L\n",
    "        k += 1  # 新生成的项集中的元素个数应不断增加\n",
    "    return L, suppData  # 返回所有满足条件的频繁项集的列表，和所有候选项集的支持度信息\n",
    "\n",
    "\n",
    "def calcConf(freqSet, H, supportData, brl, minConf=0.7):  # 规则生成与评价\n",
    "    '''\n",
    "        计算规则的可信度，返回满足最小可信度的规则。\n",
    "        freqSet(frozenset):频繁项集\n",
    "        H(frozenset):频繁项集中所有的元素\n",
    "        supportData(dic):频繁项集中所有元素的支持度\n",
    "        brl(tuple):满足可信度条件的关联规则\n",
    "        minConf(float):最小可信度\n",
    "    '''\n",
    "    prunedH = []\n",
    "    for conseq in H:\n",
    "        conf = supportData[freqSet] / supportData[freqSet - conseq]\n",
    "        if conf >= minConf:\n",
    "            print(freqSet - conseq, '-->', conseq, 'conf:', conf)\n",
    "            brl.append((freqSet - conseq, conseq, conf))\n",
    "            prunedH.append(conseq)\n",
    "    return prunedH\n",
    "\n",
    "\n",
    "def rulesFromConseq(freqSet, H, supportData, brl, minConf=0.7):\n",
    "    '''\n",
    "        对频繁项集中元素超过2的项集进行合并。\n",
    "        freqSet(frozenset):频繁项集\n",
    "        H(frozenset):频繁项集中的所有元素，即可以出现在规则右部的元素\n",
    "        supportData(dict):所有项集的支持度信息\n",
    "        brl(tuple):生成的规则\n",
    "    '''\n",
    "    m = len(H[0])\n",
    "    if len(freqSet) > m + 1:  # 查看频繁项集是否足够大，以到于移除大小为 m的子集，否则继续生成m+1大小的频繁项集\n",
    "        Hmp1 = aprioriGen(H, m + 1)\n",
    "        Hmp1 = calcConf(freqSet, Hmp1, supportData, brl, minConf)  # 对于新生成的m+1大小的频繁项集，计算新生成的关联规则的右则的集合\n",
    "        if len(Hmp1) > 1:  # 如果不止一条规则满足要求（新生成的关联规则的右则的集合的大小大于1），进一步递归合并，\n",
    "            # 这样做的结果就是会有“[1|多]->多”(右边只会是“多”，因为合并的本质是频繁子项集变大，\n",
    "            # 而calcConf函数的关联结果的右侧就是频繁子项集）的关联结果\n",
    "            rulesFromConseq(freqSet, Hmp1, supportData, brl, minConf)\n",
    "\n",
    "\n",
    "def generateRules(L, supportData, minConf=0.7):\n",
    "    '''\n",
    "        根据频繁项集和最小可信度生成规则。\n",
    "        L(list):存储频繁项集\n",
    "        supportData(dict):存储着所有项集（不仅仅是频繁项集）的支持度\n",
    "        minConf(float):最小可信度\n",
    "    '''\n",
    "    bigRuleList = []\n",
    "    for i in range(1, len(L)):\n",
    "        for freqSet in L[i]:  # 对于每一个频繁项集的集合freqSet\n",
    "            H1 = [frozenset([item]) for item in freqSet]\n",
    "            if i > 1:  # 如果频繁项集中的元素个数大于2，需要进一步合并，这样做的结果就是会有“[1|多]->多”(右边只会是“多”，\n",
    "                # 因为合并的本质是频繁子项集变大，而calcConf函数的关联结果的右侧就是频繁子项集），的关联结果\n",
    "                rulesFromConseq(freqSet, H1, supportData, bigRuleList, minConf)\n",
    "            else:\n",
    "                calcConf(freqSet, H1, supportData, bigRuleList, minConf)\n",
    "\n",
    "    sorted(bigRuleList)\n",
    "    return bigRuleList\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lwl/Documents/GitHub/AprioriAlgorithm/Config/__init__.py:22: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  ans = np.array(ans)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDat = loadTest()  # 导入数据集\n",
    "\n",
    "myDat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n",
      "iter is  2\n",
      "gen coast:0.00014782s\n",
      "435\n",
      "scan coast:0.43931198s\n",
      "iter is  3\n",
      "gen coast:0.00477099s\n",
      "2090\n",
      "scan coast:2.59730101s\n",
      "iter is  4\n",
      "gen coast:0.07675385s\n",
      "5253\n",
      "scan coast:8.06661677s\n",
      "iter is  5\n",
      "gen coast:0.51115584s\n",
      "8383\n",
      "scan coast:15.15855479s\n",
      "iter is  6\n",
      "gen coast:2.09867597s\n",
      "9688\n",
      "scan coast:19.87523794s\n",
      "iter is  7\n",
      "gen coast:5.71474218s\n",
      "9097\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "t = time.time()\n",
    "\n",
    "L, suppData = apriori(myDat, para['minSupport'])  # 选择频繁项集\n",
    "# print(u\"频繁项集L：\", suppData)\n",
    "# print(u\"所有候选项集的支持度信息：\", suppData)\n",
    "print(f'花费的时间为:{time.time() - t:.8f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in L:\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Apriori 多进程 算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Config import *\n",
    "import ray\n",
    "ray.shutdown()\n",
    "import ray\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frozenset() 返回一个冻结的集合，冻结后集合不能再添加或删除任何元素。\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 返回只有单个元素的候选集\n",
    "def createC1(dataSet):\n",
    "    '''\n",
    "        构建初始候选项集的列表，即所有候选项集只包含一个元素，\n",
    "        C1是大小为1的所有候选项集的集合\n",
    "    '''\n",
    "    C1 = []\n",
    "    for transaction in dataSet:\n",
    "        for item in transaction:\n",
    "            if [item] not in C1:\n",
    "                C1.append([item])\n",
    "    C1.sort()\n",
    "    # return map( frozenset, C1 )\n",
    "    # return [var for var in map(frozenset,C1)]\n",
    "    return [frozenset(var) for var in C1]\n",
    "\n",
    "\n",
    "@ray.remote\n",
    "def scanD(D, Ck, minSupport):\n",
    "    '''\n",
    "        计算Ck中的项集在数据集合D(记录或者transactions)中的支持度,\n",
    "        返回满足最小支持度的项集的集合，和所有项集支持度信息的字典。\n",
    "    '''\n",
    "    print(len(Ck))\n",
    "    ssCnt = {}\n",
    "    for tid in D:  # 对于每一条transaction\n",
    "        for can in Ck:  # 对于每一个候选项集can，检查是否是transaction的一部分 # 即该候选can是否得到transaction的支持\n",
    "            flag = True\n",
    "            for i in can:\n",
    "                if i not in tid:\n",
    "                    flag = False\n",
    "                    \n",
    "            if flag:\n",
    "                ssCnt[can] = ssCnt.get(can, 0) + 1\n",
    "\n",
    "    numItems = float(len(D))\n",
    "    # print(\"ssCnt is\",ssCnt)\n",
    "    retList = []\n",
    "    supportData = {}\n",
    "    for key in ssCnt:\n",
    "        support = ssCnt[key] / numItems  # 每个项集的支持度\n",
    "        if support >= minSupport:  # 将满足最小支持度的项集，加入retList\n",
    "            retList.insert(0, key)\n",
    "        supportData[key] = support  # 汇总支持度数据\n",
    "    return retList, supportData\n",
    "import copy\n",
    "def total_scan(D, Ck, minSupport):\n",
    "    # 分为10核\n",
    "    Cs = []\n",
    "    Ck =list(Ck)\n",
    "    print(len(Ck))\n",
    "    single_size = int(len(Ck)/7)\n",
    "#     for i in range(10):\n",
    "#         Cs.append(Ck[i* single_size : (i+1)*single_size])\n",
    "#     Cs.append(Ck[10 * single_size: -1])\n",
    "#     ans = [single_scan.remote(D, Ci, minSupport) for Ci in Cs]\n",
    "    \n",
    "    t1 = single_scan.remote(copy.deepcopy(D), Ck[0:single_size], minSupport)\n",
    "    t2 = single_scan.remote(copy.deepcopy(D), Ck[single_size:2*single_size], minSupport)\n",
    "    t3 = single_scan.remote(copy.deepcopy(D), Ck[single_size*2:3*single_size], minSupport)\n",
    "    t4 = single_scan.remote(copy.deepcopy(D), Ck[single_size*3:4*single_size], minSupport)\n",
    "    t5 = single_scan.remote(copy.deepcopy(D), Ck[single_size*4:5*single_size], minSupport)\n",
    "    t6 = single_scan.remote(copy.deepcopy(D), Ck[single_size*5:6*single_size], minSupport)\n",
    "    t7 = single_scan.remote(copy.deepcopy(D), Ck[single_size*6:7*single_size], minSupport)\n",
    "    t8 = single_scan.remote(copy.deepcopy(D), Ck[single_size*7:8*single_size], minSupport)\n",
    "    \n",
    "    ans =[t1,t2,t3,t4,t5,t6,t7,t8]\n",
    "    \n",
    "    ans = ray.get(ans)\n",
    "    tmp = {}\n",
    "    for i in ans:\n",
    "        for j in i:\n",
    "            if i[j] > minSupport:\n",
    "                tmp[j] = i[j]\n",
    "#     print(tmp)\n",
    "    ret_list = [i for i in tmp]\n",
    "    return ret_list, tmp\n",
    "    \n",
    "\n",
    "@ray.remote\n",
    "def single_scan(D, Ck, minS):\n",
    "    r, c = ray.get(scanD.remote(D, Ck,minS))\n",
    "    return c\n",
    "\n",
    "\n",
    "def aprioriGen(Lk, k):  # Aprior算法\n",
    "    '''\n",
    "        由初始候选项集的集合Lk生成新的生成候选项集，\n",
    "        k表示生成的新项集中所含有的元素个数\n",
    "        注意其生成的过程中，首选对每个项集按元素排序，然后每次比较两个项集，只有在k-1项相同时才将这两项合并。这样做是因为函数并非要两两合并各个集合，那样生成的集合并非都是k+1项的。在限制项数为k+1的前提下，只有在前k-1项相同、最后一项不相同的情况下合并才为所需要的新候选项集。\n",
    "    '''\n",
    "    retList = set()\n",
    "    lenLk = len(Lk)\n",
    "    for i in range(lenLk):\n",
    "        for j in range(i + 1, lenLk):\n",
    "            \n",
    "            L1 = Lk[i]\n",
    "            L2 = Lk[j]\n",
    "            cnt =0\n",
    "            for m in L1:\n",
    "                if m in L2:\n",
    "                    cnt+=1\n",
    "            if cnt == k-2:\n",
    "                retList.add(Lk[i] | Lk[j])\n",
    "    return retList\n",
    "\n",
    "\n",
    "def apriori(dataSet, minSupport=0.5):\n",
    "    \"\"\"\n",
    "    该函数为Apriori算法的主函数，按照前述伪代码的逻辑执行。Ck表示项数为k的候选项集，最初的C1通过createC1()函数生成。Lk表示项数为k的频繁项集，supK为其支持度，Lk和supK由scanD()函数通过Ck计算而来。\n",
    "    :param dataSet:\n",
    "    :param minSupport:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    C1 = createC1(\n",
    "        dataSet)  # 构建初始候选项集C1  [frozenset({1}), frozenset({2}), frozenset({3}), frozenset({4}), frozenset({5})]\n",
    "\n",
    "    D = [set(var) for var in dataSet]  # 集合化数据集\n",
    "    L1, suppData = ray.get(scanD.remote(D, C1, minSupport) ) # 构建初始的频繁项集，即所有项集只有一个元素\n",
    "    L = [L1]  # 最初的L1中的每个项集含有一个元素，新生成的\n",
    "    # print()\n",
    "    k = 2  # 项集应该含有2个元素，所以 k=2\n",
    "\n",
    "    while (len(L[k - 2]) > 0):\n",
    "        print(\"iter is \", k)\n",
    "        t = time.time()\n",
    "        Ck = aprioriGen(L[k - 2], k)\n",
    "        print(f'gen coast:{time.time() - t:.8f}s')\n",
    "        \n",
    "        t = time.time()\n",
    "        Lk, supK = total_scan(D, Ck, minSupport) # 筛选最小支持度的频繁项集\n",
    "        print(f'scan coast:{time.time() - t:.8f}s')\n",
    "        # print(\"iter is \")\n",
    "        # print(Ck)\n",
    "        # print(Lk)\n",
    "        # print()\n",
    "        suppData.update(supK)  # 将新的项集的支持度数据加入原来的总支持度字典中\n",
    "        L.append(Lk)  # 将符合最小支持度要求的项集加入L\n",
    "        k += 1  # 新生成的项集中的元素个数应不断增加\n",
    "    return L, suppData  # 返回所有满足条件的频繁项集的列表，和所有候选项集的支持度信息\n",
    "\n",
    "\n",
    "def calcConf(freqSet, H, supportData, brl, minConf=0.7):  # 规则生成与评价\n",
    "    '''\n",
    "        计算规则的可信度，返回满足最小可信度的规则。\n",
    "        freqSet(frozenset):频繁项集\n",
    "        H(frozenset):频繁项集中所有的元素\n",
    "        supportData(dic):频繁项集中所有元素的支持度\n",
    "        brl(tuple):满足可信度条件的关联规则\n",
    "        minConf(float):最小可信度\n",
    "    '''\n",
    "    prunedH = []\n",
    "    for conseq in H:\n",
    "        conf = supportData[freqSet] / supportData[freqSet - conseq]\n",
    "        if conf >= minConf:\n",
    "            print(freqSet - conseq, '-->', conseq, 'conf:', conf)\n",
    "            brl.append((freqSet - conseq, conseq, conf))\n",
    "            prunedH.append(conseq)\n",
    "    return prunedH\n",
    "\n",
    "\n",
    "def rulesFromConseq(freqSet, H, supportData, brl, minConf=0.7):\n",
    "    '''\n",
    "        对频繁项集中元素超过2的项集进行合并。\n",
    "        freqSet(frozenset):频繁项集\n",
    "        H(frozenset):频繁项集中的所有元素，即可以出现在规则右部的元素\n",
    "        supportData(dict):所有项集的支持度信息\n",
    "        brl(tuple):生成的规则\n",
    "    '''\n",
    "    m = len(H[0])\n",
    "    if len(freqSet) > m + 1:  # 查看频繁项集是否足够大，以到于移除大小为 m的子集，否则继续生成m+1大小的频繁项集\n",
    "        Hmp1 = aprioriGen(H, m + 1)\n",
    "        Hmp1 = calcConf(freqSet, Hmp1, supportData, brl, minConf)  # 对于新生成的m+1大小的频繁项集，计算新生成的关联规则的右则的集合\n",
    "        if len(Hmp1) > 1:  # 如果不止一条规则满足要求（新生成的关联规则的右则的集合的大小大于1），进一步递归合并，\n",
    "            # 这样做的结果就是会有“[1|多]->多”(右边只会是“多”，因为合并的本质是频繁子项集变大，\n",
    "            # 而calcConf函数的关联结果的右侧就是频繁子项集）的关联结果\n",
    "            rulesFromConseq(freqSet, Hmp1, supportData, brl, minConf)\n",
    "\n",
    "\n",
    "def generateRules(L, supportData, minConf=0.7):\n",
    "    '''\n",
    "        根据频繁项集和最小可信度生成规则。\n",
    "        L(list):存储频繁项集\n",
    "        supportData(dict):存储着所有项集（不仅仅是频繁项集）的支持度\n",
    "        minConf(float):最小可信度\n",
    "    '''\n",
    "    bigRuleList = []\n",
    "    for i in range(1, len(L)):\n",
    "        for freqSet in L[i]:  # 对于每一个频繁项集的集合freqSet\n",
    "            H1 = [frozenset([item]) for item in freqSet]\n",
    "            if i > 1:  # 如果频繁项集中的元素个数大于2，需要进一步合并，这样做的结果就是会有“[1|多]->多”(右边只会是“多”，\n",
    "                # 因为合并的本质是频繁子项集变大，而calcConf函数的关联结果的右侧就是频繁子项集），的关联结果\n",
    "                rulesFromConseq(freqSet, H1, supportData, bigRuleList, minConf)\n",
    "            else:\n",
    "                calcConf(freqSet, H1, supportData, bigRuleList, minConf)\n",
    "\n",
    "    sorted(bigRuleList)\n",
    "    return bigRuleList\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDat = loadTest()  # 导入数据集\n",
    "myDat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "t = time.time()\n",
    "\n",
    "L, suppData = apriori(myDat, para['minSupport'])  # 选择频繁项集\n",
    "# print(u\"频繁项集L：\", suppData)\n",
    "# print(u\"所有候选项集的支持度信息：\", suppData)\n",
    "print(f'花费的时间为:{time.time() - t:.8f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in L:\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多进程实验结果\n",
    "\n",
    "不难看出，实验正确性一致。\n",
    "\n",
    "并且实验的性能得到了巨大提升。\n",
    "\n",
    "我这里使用10个进程，总效率提升了5倍。单scan部分提升了接近10倍。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
